<br />
<div align="center">
  <h3 align="center">Ollama + Open Webui + Ollama3</h3>
  <p align="center">
    ðŸš€ Ollama + Open Webui + Ollama3 em ambiente local
    <br />
    <br />
  </p>
  </p>
</div>

## Para executar o projeto em seu ambiente local, basta clonar ou realizar o download do projeto em sua maquina local.

```sh
git clone git@github.com:diegorondao/llama3-open-web-ui-run-locally.git
```

Acessar o diretÃ³rio do projeto

```sh
cd llama3-open-web-ui-run-locally
```
VocÃª deve ter o Docker Desktop instalado e logado. Execute este comando no prompt de comando.
```
docker-compose up 
```
<br />

Abra o seu navegador no endereÃ§o http://localhost:3000/auth
![imagem (3)](https://github.com/user-attachments/assets/b4c83abf-db50-48c4-83fa-4891f355c56c)

<br />

Home
![imagem (1)](https://github.com/user-attachments/assets/828a92ed-e188-4f7b-8fa3-3e5f789f6cff)

<br />

Baixe um modelo de IA pelo open-webui (todos os modelos: https://github.com/ollama/ollama)
![imagem (2)](https://github.com/user-attachments/assets/c8edef2e-967b-4c3d-89f8-5661d4076c60)

